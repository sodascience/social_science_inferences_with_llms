# Addressing LLM-related Measurement Error in Social Science Modeling Research
Addressing LLM-related measurement error in social science modeling research.

With the advent of large language models (LLMs), the collection of measurements related to **social science constructs** (e.g., personality traits, political attitudes, human values) has become easier, faster and more affordable. These measurements are subsequently used for **modelling of societal and group processes** that social scientists typically engage in, where **inferences from samples to populations are also made**. Valid modelling and inferences, however, requires high-quality measurements or at the very least, **methods to deal with the presence of measurement error**. Just like traditional questionnaire-based measurements, LLM-based measurements have been shown to suffer from validity and reliability issues. 

While there is an abundance of research literature in dealing with measurement error, they focus on questionnaire-based measurement error. **It is unclear yet how measurement issues arising from LLMs should be handled in social science modelling research**. 

This study has two primary objectives. First, we **review existing literature** to identify practices for addressing LLM-related measurement error, both in computer science and in social sciences. Second, we synthesise these findings with existing measurement modelling literature to propose **a practical framework for making valid inferences using LLM-based measurements in social sciences**. By bridging the gap between LLM prediction capabilities and social science inference requirements, our framework aims to enhance the reliability and validity of social science research outcomes in the era of LLMs.

# Literature Overview
